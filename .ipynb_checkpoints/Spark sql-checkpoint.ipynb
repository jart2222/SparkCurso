{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f6153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "findspark.init()\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf88e25b-0b57-49ac-9e3c-b114fd1bd61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_subarea.output_text.output_stream.output_stdout > pre {\n",
    "  width:max-content;\n",
    "}\n",
    ".p-Widget.jp-RenderedText.jp-OutputArea-output > pre {\n",
    "  width:max-content;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5769ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd=sc.parallelize([item for item in range(10)]).map(lambda x: (x, x**2))\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b44dc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= rdd.toDF([\"numero\",\"cuadrado\"])\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab3f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4e3232",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1=sc.parallelize([(1, \"Jose\", 35.5),(2,\"Teresa\",54.3),(3,\"Katia\", 12.7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b36c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Via uno\n",
    "\n",
    "esquema1= StructType(\n",
    "    [\n",
    "     StructField(\"id\", IntegerType(), True),\n",
    "     StructField(\"nombre\", StringType(), True),\n",
    "     StructField(\"saldo\", DoubleType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Via dos\n",
    "\n",
    "esquema2=\"`id` INT, `nombre` STRING, `saldo` DOUBLE\"\n",
    "\n",
    "df1=spark.createDataFrame(rdd1, schema=esquema1)\n",
    "\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10389bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc69217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame mediante la lectura de un archivo de texto\n",
    "\n",
    "df = spark.read.text('./data/dataTXT.txt')\n",
    "\n",
    "df.show()\n",
    "\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a458be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame mediante la lectura de un archivo csv\n",
    "\n",
    "df1 = spark.read.csv('./data/dataCSV.csv')\n",
    "\n",
    "df1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d4334",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = spark.read.option('header', 'true').csv('./data/dataCSV.csv')\n",
    "\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bdd92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2 = spark.read.option('header', 'true').option('delimiter', '|').csv('./data/dataTab.txt')\n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce057ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType\n",
    "\n",
    "json_schema =  StructType(\n",
    "    [\n",
    "     StructField('color', StringType(), True),\n",
    "     StructField('edad', IntegerType(), True),\n",
    "     StructField('fecha', DateType(), True),\n",
    "     StructField('pais', StringType(), True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "df4 = spark.read.schema(json_schema).json('./data/dataJSON.json')\n",
    "\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae608e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = spark.read.parquet('./data/dataPARQUET.parquet')\n",
    "\n",
    "df5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031b160",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Otra alternativa para leer desde una fuente de datos parquet en este caso\n",
    "\n",
    "df6 = spark.read.format('parquet').load('./data/dataPARQUET.parquet')\n",
    "\n",
    "df6.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ebc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('./data/dataPARQUET.parquet')\n",
    "\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc7e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primera alternativa para referirnos a las columnas\n",
    "\n",
    "df.select('title').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd7384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.select(col('title'), col('likes')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8796cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select\n",
    "\n",
    "df = spark.read.parquet('./data/datos.parquet')\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98b2a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.select(col('video_id')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b68b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('video_id', 'trending_date').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1203bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta vía nos dará error\n",
    "\n",
    "df.select(\n",
    "    'likes',\n",
    "    'dislikes',\n",
    "    ('likes' - 'dislikes')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    col('likes'),\n",
    "    col('dislikes'),\n",
    "    (col('likes') - col('dislikes')).alias('aceptacion')\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d1b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selectExpr\n",
    "df.selectExpr('likes', 'dislikes', '(likes - dislikes) as aceptacion').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c652ed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.selectExpr(\"count(distinct(video_id)) as videos\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c15ae1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               title|\n",
      "+--------------------+\n",
      "|WE WANT TO TALK A...|\n",
      "|WE WANT TO TALK A...|\n",
      "|WE WANT TO TALK A...|\n",
      "|WE WANT TO TALK A...|\n",
      "|WE WANT TO TALK A...|\n",
      "|WE WANT TO TALK A...|\n",
      "|WE WANT TO TALK A...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_prueba = spark.read.parquet('./data/datos.parquet')\n",
    "df_prueba2=df_prueba.select('title').filter(col('title').like('%WE WANT TO TALK%'))\n",
    "df_prueba2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a490452",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Filter\n",
    "df = spark.read.parquet('./data/datos.parquet')\n",
    "df.show( )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db715c63",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df.filter(col('video_id') == \"2kyS6SvSYSE\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451c5af4-be0f-407d-95d4-980c2c2fc4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Where\n",
    "df1 = spark.read.parquet('./data/datos.parquet').where(col(\"trending_date\") != '17.14.11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04578e5c-46c2-4cf9-b8f0-b446ad0f8343",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f76e1-ab4f-48d7-8763-f598e4da9d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=spark.read.parquet('./data/datos.parquet').where(col(\"likes\")>5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d8c8fe-93da-457b-9995-7b5f954ffd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.filter(col(\"trending_date\") != '17.14.11').filter(col(\"likes\")<7000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
